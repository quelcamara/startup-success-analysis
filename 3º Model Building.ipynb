{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blessed-drive",
   "metadata": {},
   "source": [
    "## <font color='#607c8e'>Startup's Success Analysis</font>\n",
    "<font color='#cb416b'>Data Science Foundation Program BootCamp<br/></font>\n",
    "Raquel Câmara Porto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-yellow",
   "metadata": {},
   "source": [
    "<b>Objective: Predicting the profit of a new Startup based on certain features and deciding whether one should invest in a particular startup or not.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-polymer",
   "metadata": {},
   "source": [
    "### <font color='#3c4142'>Model Building</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-nebraska",
   "metadata": {},
   "source": [
    "First of all, in order to keep using the variables and dataset from other Notebooks, it is necessary to import the files into this Notebook. For this, Jupyter provide us with a Built-in magic command <font color='#9a0eea'><b>%</b></font>run that allows us to have access to all the methods and variables created on some other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accepted-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# importing variables and libs\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%run \"./2º Exploratory Data Analysis (EDA).ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-letter",
   "metadata": {},
   "source": [
    "To make use of the features and target variables on the machine learning models, it is necessary to first convert their types into an array of values the models will be able to read. So, all the categorical data must be transformed into numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expired-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the variables into an array of the values\n",
    "features_vals = features.values\n",
    "target_vals = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heavy-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming State column in features variable into a Numerical type with OneHotEncoder()\n",
    "transformer = ColumnTransformer(transformers=\n",
    "                                [(\"features\", OneHotEncoder(),[3])],\n",
    "                                remainder='passthrough')\n",
    "\n",
    "features_vals = transformer.fit_transform(features_vals.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mighty-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the transformed data\n",
    "features_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-wrong",
   "metadata": {},
   "source": [
    "However, the features variable still is an <b>object</b> dtype.<br/>\n",
    "To meet the criterias for the model creation, this variable will be transformed into a normal <b>array</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interesting-pillow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n",
       "        9.9814710e+04, 3.6286136e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n",
       "        1.4719887e+05, 1.2771682e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n",
       "        1.4553006e+05, 3.2387668e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n",
       "        1.4871895e+05, 3.1161329e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n",
       "        1.0867917e+05, 3.0498162e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n",
       "        1.1059411e+05, 2.2916095e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n",
       "        9.1790610e+04, 2.4974455e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n",
       "        1.2732038e+05, 2.4983944e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n",
       "        1.3549507e+05, 2.5266493e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n",
       "        1.5654742e+05, 2.5651292e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n",
       "        1.2261684e+05, 2.6177623e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n",
       "        1.2159755e+05, 2.6434606e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n",
       "        1.4507758e+05, 2.8257431e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n",
       "        1.1417579e+05, 2.9491957e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n",
       "        1.5351411e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n",
       "        1.1386730e+05, 2.9866447e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n",
       "        1.5377343e+05, 2.9973729e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n",
       "        1.2278275e+05, 3.0331926e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n",
       "        1.0575103e+05, 3.0476873e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n",
       "        9.9281340e+04, 1.4057481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n",
       "        1.3955316e+05, 1.3796262e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n",
       "        1.4413598e+05, 1.3405007e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n",
       "        1.2786455e+05, 3.5318381e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n",
       "        1.8264556e+05, 1.1814820e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n",
       "        1.5303206e+05, 1.0713838e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n",
       "        1.1564128e+05, 9.1131240e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n",
       "        1.5270192e+05, 8.8218230e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n",
       "        1.2921961e+05, 4.6085250e+04],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n",
       "        1.0305749e+05, 2.1463481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n",
       "        1.5769392e+05, 2.1079767e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n",
       "        8.5047440e+04, 2.0551764e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n",
       "        1.2705621e+05, 2.0112682e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n",
       "        5.1283140e+04, 1.9702942e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n",
       "        6.5947930e+04, 1.8526510e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n",
       "        8.2982090e+04, 1.7499930e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n",
       "        1.1854605e+05, 1.7279567e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n",
       "        8.4710770e+04, 1.6447071e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n",
       "        9.6189630e+04, 1.4800111e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n",
       "        1.2738230e+05, 3.5534170e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n",
       "        1.5480614e+05, 2.8334720e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n",
       "        1.2415304e+05, 1.9039300e+03],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n",
       "        1.1581621e+05, 2.9711446e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the features dtype as float values\n",
    "features_vals = features_vals.astype(float)\n",
    "features_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-flush",
   "metadata": {},
   "source": [
    "With the data ready to be used, we separate the values of both features and target variables into <b>training</b> and <b>testing</b> data for our models to be fed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worth-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the values into training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features_vals,\n",
    "                                                    target_vals,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sharing-morrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 6) (10, 6) (40,) (10,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the samples shapes\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-latest",
   "metadata": {},
   "source": [
    "### <font color='#3c4142'>Decision Tree Regression Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "registered-roberts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(min_samples_leaf=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the fisrt model using Decision Tree Regression\n",
    "DTR = DecisionTreeRegressor(min_samples_leaf=3)\n",
    "DTR.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "demographic-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9610596256645947\n",
      "0.9810304512387338\n"
     ]
    }
   ],
   "source": [
    "# Checking the scores of both training and testing samples\n",
    "print(DTR.score(X_train, Y_train))\n",
    "print(DTR.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-pottery",
   "metadata": {},
   "source": [
    "Using a max_depth of 2 for, we achieved a satisfactory result with a <b>generalized model</b>.<br/>\n",
    "\n",
    "As the name implies, a generalized model is a model that has the ability to generalize well from our training data when facing unseen data, and does not perform <b>overfitting</b>.<br/>\n",
    "\n",
    "Overfitting occurs when a model goes <b>too deep</b> on learning the training data to the point of start making predictions based on <b>noises</b> (outliers and randomness). If that happens, we will see an algorithm that can perform oddly and extraordinarily well on its training data, but very poorly on any new and unseen data presented to it. And that happens because the model becomes too flexible in learning from the data presented and as a consequence, it starts making predictions with higher variances.\n",
    "\n",
    "A well regularized model should perform properly on unseen data and not only on its training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-memorial",
   "metadata": {},
   "source": [
    "### <font color='#3c4142'>Random Forest Regression Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "above-honolulu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=2, random_state=8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the second model using Random Forest Regression\n",
    "RF = RandomForestRegressor(n_estimators=2, max_depth=3, random_state=8)\n",
    "RF.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informative-custody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9673556712742566\n",
      "0.9225856875164918\n"
     ]
    }
   ],
   "source": [
    "# Checking the scores of both training and testing samples\n",
    "print(RF.score(X_train, Y_train))\n",
    "print(RF.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suitable-placement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator: 4\n",
      "- Training Score: 0.96883\n",
      "- Testing Score:  0.98413\n",
      "estimator: 5\n",
      "- Training Score: 0.97149\n",
      "- Testing Score:  0.97399\n",
      "estimator: 6\n",
      "- Training Score: 0.97392\n",
      "- Testing Score:  0.96964\n",
      "estimator: 7\n",
      "- Training Score: 0.97574\n",
      "- Testing Score:  0.96183\n",
      "estimator: 8\n",
      "- Training Score: 0.97441\n",
      "- Testing Score:  0.96492\n",
      "estimator: 9\n",
      "- Training Score: 0.97468\n",
      "- Testing Score:  0.96784\n"
     ]
    }
   ],
   "source": [
    "# Looking for better results\n",
    "for i in range(4,10):\n",
    "    RF=RandomForestRegressor(n_estimators=i, max_depth=3, random_state=8)\n",
    "    RF.fit(X_train, Y_train.ravel())\n",
    "    train_score = RF.score(X_train, Y_train)\n",
    "    test_score = RF.score(X_test, Y_test)\n",
    "\n",
    "    print(\"estimator: %d\" %i)\n",
    "    print(\"- Training Score: %.5f\" %train_score)\n",
    "    print(\"- Testing Score:  %.5f\" %test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-perry",
   "metadata": {},
   "source": [
    "We can conclude that with 4 estimators, a max depth of 3 and a random state of 8, a better generalized model could be derived for this particular dataset.<br/>\n",
    "That happened when the model had its testing score performing better than the training score. It means that the model is able to fit very well the data, and the independent variable (Y) can explain most of the changes on the dependet variables (X).<br/>\n",
    "\n",
    "The score method returns the coefficient of determination <b>R²</b> of the prediction, and it indicates the percentage of the variance in the dependent variable that the independent variables can explain. R-squared measures the strength of the <b>relationship</b> between the model and the X variables on a 0 – 100% scale.<br/>\n",
    "\n",
    "With the model in hands, we can now start graphically analyze the original data with the predicted data from both models and come to a conclusion about the starrup's profits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
